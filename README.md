# C-Evalï¼š A Multi-Level Multi-Discipline Chinese Evaluation Suite

<p align="center">
   ğŸŒ <a href="https://cevalbenchmark.com/" target="_blank">ç½‘ç«™</a> â€¢ ğŸ¤— <a href="https://huggingface.co/datasets/ceval/ceval-exam" target="_blank">Hugging Face</a> â€¢ â¬ <a href="https://onedrive.live.com/download?cid=19737A21B01C55D4&resid=19737A21B01C55D4!983&authkey=AGch_tVH959ZJiw" target="_blank">ä¸‹è½½</a> â€¢  âœ‰ï¸ <a href="mailto:ceval.benchmark@gmail.com">é‚®ç®±</a> â€¢ ğŸ“ƒ <a href="https://google.com"" target="_blank">è®ºæ–‡</a> <br>
</p>



### ä»‹ç»

C-Evalæ˜¯ä¸€ä¸ªç»¼åˆæ€§çš„è¯­è¨€æ¨¡å‹ä¸­æ–‡è¯„ä¼°ç»„ä»¶ï¼Œæ—¨åœ¨è¯„ä¼°è¯­è¨€æ¨¡å‹åœ¨ä¸­æ–‡è¯­å¢ƒä¸­çš„çŸ¥è¯†å’Œæ¨ç†èƒ½åŠ›ã€‚C-Eval åŒ…æ‹¬å››ä¸ªéš¾åº¦çº§åˆ«çš„å¤šé¡¹é€‰æ‹©é¢˜ï¼šåˆä¸­ã€é«˜ä¸­ã€å¤§å­¦å’Œä¸“ä¸šæµ‹è¯•ã€‚è¿™äº›é—®é¢˜æ¶µç›– 52 ä¸ªä¸åŒçš„å­¦ç§‘ï¼ŒåŒ…æ‹¬STEMï¼Œäººæ–‡ç§‘å­¦ï¼Œç¤¾ä¼šç§‘å­¦å’Œå…¶ä»–å››ä¸ªå¤§ç±»ã€‚è¿›ä¸€æ­¥æ¢ç´¢C-Evalï¼Œè¯·è®¿é—®æˆ‘ä»¬çš„[ç½‘ç«™](https://cevalbenchmark.com/)ã€‚æˆ‘ä»¬åœ¨ç½‘ç«™ä¸Šé¢ç»™å‡ºäº†52ä¸ªç§‘ç›®ä»¥åŠå¯¹åº”çš„[æ ·ä¾‹](https://cevalbenchmark.com/static/explore.html)ã€‚å¹¶ä¸”ï¼Œæ‚¨å¯ä»¥é€šè¿‡æˆ‘ä»¬çš„ç½‘ç«™ä¸Šä¼ æµ‹è¯•ç»“æœï¼Œè·å¾—å¯¹åº”çš„åˆ†æ•°ï¼Œåœ¨[æ’è¡Œæ¦œ](https://cevalbenchmark.com/static/leaderboard.html)å±•ç¤ºæˆç»©ã€‚



### æ’è¡Œæ¦œ



| Model               | STEM | Social Science | Humanities | Other | Average |
| ------------------- | :--: | :------------: | :--------: | :---: | :-----: |
| Random              | 25.0 |      25.0      |    25.0    | 25.0  |  25.0   |
| GPT-4               | 67.1 |      77.6      |    64.5    | 67.8  |  68.7   |
| ChatGPT             | 52.9 |      61.8      |    50.9    | 53.6  |  54.4   |
| Claude-v1.3         | 51.9 |      61.7      |    52.1    | 53.7  |  54.2   |
| MiniMax             | 40.6 |      60.3      |    56.6    | 46.6  |  49.0   |
| Claude-instant-v1.0 | 43.1 |      53.8      |    44.2    | 45.4  |  45.9   |
| GLM-130B            | 34.8 |      48.7      |    43.3    | 39.8  |  40.3   |
| Bloomz-mt           | 35.3 |      45.1      |    40.5    | 38.5  |  39.0   |
| LLaMA-65B           | 37.8 |      45.6      |    36.1    | 37.1  |  38.8   |
| ChatGLM-6B          | 30.4 |      39.6      |    37.4    | 34.5  |  34.5   |
| Chinese LLaMA-13B   | 31.6 |      37.2      |    33.6    | 32.8  |  33.3   |
| MOSS                | 28.6 |      36.8      |    31.0    | 30.3  |  31.1   |
| Chinese Alpaca-13B  | 26.0 |      27.2      |    27.8    | 26.4  |  26.7   |



### C-Eval Hardæ’è¡Œæ¦œ

æˆ‘ä»¬é€‰å–äº†C-Evalä¸­å…·æœ‰æŒ‘æˆ˜æ€§çš„æ•°å­¦ã€ç‰©ç†å’ŒåŒ–å­¦ç§‘ç›®ç»„æˆC-Eval Hardï¼ŒåŒ…æ‹¬ï¼šé«˜ç­‰æ•°å­¦ã€ç¦»æ•£æ•°å­¦ã€æ¦‚ç‡ç»Ÿè®¡ã€å¤§å­¦åŒ–å­¦ã€å¤§å­¦ç‰©ç†ã€é«˜ä¸­æ•°å­¦ã€é«˜ä¸­ç‰©ç†ã€é«˜ä¸­åŒ–å­¦å…«ä¸ªç§‘ç›®ã€‚è¿™äº›ç§‘ç›®åŒ…å«äº†å¤æ‚çš„LaTexå…¬å¼ï¼Œéœ€è¦éå‡¡çš„æ¨ç†èƒ½åŠ›æ‰èƒ½è§£å†³ã€‚

| Model               | Accuracy |
| ------------------- | :------: |
| GPT-4               |   54.9   |
| ChatGPT             |   41.4   |
| Claude-v1.3         |   39.0   |
| Claude-instant-v1.0 |   35.5   |
| LLaMA-65B           |   31.7   |
| Bloomz-mt           |   30.4   |
| GLM-130B            |   30.3   |
| Chinese LLaMA-13B   |   27.3   |
| MiniMax             |   27.3   |
| Chinese Alpaca-13B  |   27.1   |
| MOSS                |   24.0   |
| ChatGLM-6B          |   23.1   |



### ä¸‹è½½æ–¹æ³•

* æ–¹æ³•ä¸€ï¼š[Onedrive](https://onedrive.live.com/download?cid=19737A21B01C55D4&resid=19737A21B01C55D4!983&authkey=AGch_tVH959ZJiw)ä¸‹è½½

* æ–¹æ³•äºŒï¼šä½¿ç”¨[Hugging Face](https://huggingface.co/datasets/ceval/ceval-exam)ç›´æ¥åŠ è½½æ•°æ®é›†ï¼Œæ ·ä¾‹å¦‚ä¸‹ï¼š

  ```python
  from datasets import load_dataset
  dataset=load_dataset(r"ceval/ceval-exam",name="advanced_mathematics")
  ```



### ç§‘ç›®

æ•°æ®é›†ä¸»è¦åŒ…å«52ä¸ªç§‘ç›®ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

<img src="https://cevalbenchmark.com/static/img/overview.png" style="zoom: 80%;" >



### æ•°æ®æ ¼å¼

* æˆ‘ä»¬å°†æ¯ä¸€ä¸ªç§‘ç›®åˆ†ä¸ºdevï¼Œvalå’Œtestä¸‰ä¸ªé›†åˆã€‚devé›†ä¸»è¦ç”¨äºFew-shot Learningï¼ˆåŒ…å«5æ¡æ•°æ®ï¼‰ï¼Œvalé›†ç”¨äºæ¨¡å‹è°ƒè¯•ï¼Œtesté›†ç”¨äºæœ€ç»ˆæµ‹è¯•ã€‚

* æ•°æ®é‡‡ç”¨csvæ ¼å¼è¿›è¡Œå°è£…ï¼Œé‡‡ç”¨utf-8ç¼–ç æ ¼å¼ã€‚

* ä»¥è®¡ç®—æœºç½‘ç»œä¸ºä¾‹ï¼š

  ```
  id: 1
  question: æ»‘åŠ¨çª—å£çš„ä½œç”¨æ˜¯____ã€‚
  A: æµé‡æ§åˆ¶
  B: æ‹¥å¡æ§åˆ¶
  C: è·¯ç”±æ§åˆ¶
  D: å·®é”™æ§åˆ¶
  answer: A
  explantion: 1. æ»‘åŠ¨çª—å£æ˜¯ä¸€ç§æµé‡æ§åˆ¶æœºåˆ¶ï¼Œç”¨äºæ§åˆ¶å‘é€æ–¹å‘æ¥æ”¶æ–¹å‘é€æ•°æ®çš„é€Ÿç‡ï¼Œä»¥é¿å…æ¥æ”¶æ–¹æ— æ³•å¤„ç†è¿‡å¤šçš„æ•°æ®è€Œå¯¼è‡´æ•°æ®ä¸¢å¤±æˆ–æ‹¥å¡ã€‚
  ```

* **æ³¨æ„ï¼švalé›†ä¸åŒ…å«explanationï¼Œtesté›†ä¸åŒ…å«answerå’Œexplanation**ã€‚



### ä½¿ç”¨

* ä¸ºäº†æ–¹ä¾¿ä½¿ç”¨ï¼Œæˆ‘ä»¬æ•´ç†äº†52ä¸ªç§‘ç›®å¯¹åº”çš„æ–‡ä»¶åå’Œä¸­è‹±æ–‡åç§°ï¼Œå‚è€ƒsubject_mapping.jsonã€‚æ ¼å¼å¦‚ä¸‹ï¼š

  ```
  {
  	"computer_network": [
  		"Computer Network",
  		"è®¡ç®—æœºç½‘ç»œ",
  		"STEM"
  	],
  	...
  	"filename":[
  	"English Name",
  	"ä¸­æ–‡åç§°"
  	"ç±»åˆ«(STEM,Social Science,Humanities,Otherå››é€‰ä¸€)"
  	]
  }
  ```

* ä»[Hugging Face](https://huggingface.co/datasets/ceval/ceval-exam)ä½¿ç”¨ï¼Œåˆ†ä¸º"dev"ï¼Œ"validation"å’Œ"test"ä¸‰ä¸ªé›†åˆ

  ```python
  import json
  from datasets import load_dataset
  
  with open(r"subject_mapping.json",encoding="utf-8") as f:
      subject_mapping=json.load(f)
      
  for k in subject_mapping.keys():
      dataset=load_dataset(r"ceval/ceval-exam",name=k)
      print(dataset['dev'][1])
      print(dataset['validation'][1])
      print(dataset['test'][1])    
  ```

* [ä¸‹è½½](google.com)å‹ç¼©æ–‡ä»¶è§£å‹åï¼Œä½¿ç”¨Pandasç­‰åº“è¯»å–ã€‚ä¾‹å¦‚ï¼š

  ```python
  import os
  import pandas as pd
  
  File_Dir="data"
  
  with open(r"subject_mapping.json",encoding="utf-8") as f:
      subject_mapping=json.load(f)
  
  for k in subject_mapping.keys():
      for s in ["dev","val","test"]:
          pd.read_csv(os.path.join(File_Dir,s,f"{k}_{s}.csv"))
  ```

  

### Licenses

[![MIT license](https://img.shields.io/badge/License-MIT-blue.svg)](https://lbesson.mit-license.org/)

æœ¬é¡¹ç›®éµå¾ª [MIT License](http://creativecommons.org/licenses/by-nc-sa/4.0/).

[![License: CC BY-SA 4.0](https://camo.githubusercontent.com/bdc6a3b8963aa99ff57dfd6e1e4b937bd2e752bcb1f1936f90368e5c3a38f670/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d434325323042592d2d5341253230342e302d6c69676874677265792e737667)](https://creativecommons.org/licenses/by-sa/4.0/)

C-Evalæ•°æ®é›†éµå¾ª [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License](http://creativecommons.org/licenses/by-nc-sa/4.0/).
